# -*- coding: utf-8 -*-
"""MacroPrevi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v2iQyU1epP5Y_fCwnyK7lnB6Ad_hjMcT

Instala e importa dependências
"""



!pip install PyPortfolioOpt
!pip install cvxpy
!pip install pybind11
!pip install riskfolio-lib

import pandas as pd
import numpy as np
from pypfopt import EfficientFrontier
from pypfopt import risk_models
from pypfopt import expected_returns
from pypfopt import objective_functions
import matplotlib.pyplot as plt
import seaborn as sns
from pypfopt import CLA, plotting
from sklearn.linear_model import LinearRegression
import statsmodels.api as sm
import datetime
from pypfopt import HRPOpt
from pypfopt import plotting

"""Import ETFs and BDR ETFs data"""

#%% ETFs and BDR ETFs
#File Path
from google.colab import files

# Upload the file
uploaded = files.upload()

# The uploaded file is stored in a dictionary with the filename as the key
# and the file contents as the value
for fn in uploaded.keys():
  # Do something with the file
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

# Use pandas to read the Excel file
etfs_finvol = pd.read_excel('Base.xlsx', #Workbook
                   sheet_name = 'ETF Fin Vol', #Spreadsheet name
                   usecols = range(1,20), #Specify columns to use
                   skiprows = 2, #Skip first two rows
                   nrows = 278, #Specify quantity of rows to use
                   header = None) #No headers


#Display contents of DATAFRAME
print(etfs_finvol)

#Name ETFs
etfs_finvol.columns = ['BNDX11', 'USDB11', 'WRLD11', 'ALUG11', 'SMAL11', 'BOVA11', 'IVVB11', 'BOVV11', 'IMAB11', 'DIVO11',
                       'B5P211', 'IB5M11', 'IRFM11', 'SPXI11', 'SMAC11', 'URET11', 'XFIX11', 'GOLD11', 'ACWI11']

#Mean Financial Vol
etfs_finvol.tail(12) #Take last 12 months of negotiation
etfs_finvol_colmeans = np.mean(etfs_finvol.tail(12), axis = 0)

# Convert to Pandas Series and set float_format
etfs_finvol_colmeans_series = pd.Series(etfs_finvol_colmeans)
pd.set_option('display.float_format', lambda x: '%.3f' % x)

# Print the result
print("\nDaily financial volume means of the last 12 months:")
print(etfs_finvol_colmeans_series)

# Use pandas to read the Excel file
bdrs_finvol = pd.read_excel('Base.xlsx', #Workbook path
                   sheet_name = 'BDR ETF Fin Vol', #Spreadsheet name
                   usecols = range(1,12), #Specify columns to use
                   skiprows = 2, #Skip first two rows
                   nrows = 40, #Specify quantity of rows to use
                   header = None) #No headers

#Display contents of DATAFRAME
print(bdrs_finvol)

#Name ETFs
bdrs_finvol.columns = ['BSRE39', 'BTLT39', 'BIEI39', 'BIYT39', 'BUSR39', 'BGRT39', 'BIAU39', 'BCOM39', 'BSHV39', 'BGOV39',
                       'BIPZ39']


#Mean Financial Vol
bdrs_finvol.tail(12) #Take last 12 months of negotiation
bdrs_finvol_colmeans = np.mean(bdrs_finvol.tail(12), axis = 0)

# Convert to Pandas Series and set float_format
bdrs_finvol_colmeans_series = pd.Series(bdrs_finvol_colmeans)
pd.set_option('display.float_format', lambda x: '%.3f' % x)

# Print the result
print("\nDaily financial volume means of the last 12 months:")
print(bdrs_finvol_colmeans_series)

"""Indexes Data"""

# Use pandas to read the Excel file
assets_returns = pd.read_excel('Base.xlsx', #Workbook path
                   sheet_name = 'Indexes Returns', #Spreadsheet name
                   usecols = range(1,46), #Specify columns to use
                   skiprows = 2, #Skip first two rows
                   nrows = 289, #Specify quantity of rows to use
                   header = None #No headers
                   )



#Subset more liquid options
assets_returns_selected = assets_returns.iloc[:,# All rows
                                              [   0,#CDI
                                                  2, #FTSE Nareit Equty REITs
                                                  6, #MSCI US IMI/Real Estate 25-50
                                                  12, #7-10 Treasury
                                                  14, #20+ Treasury
                                                  16, #General TIPS
                                                  24, #Ibov
                                                  27, #IHFA
                                                  28, #IMA-B
                                                  29, #IMA-B 5
                                                  30, #IMA-B 5+
                                                  31, #IRF-M
                                                  32, #MSCI ACWI
                                                  36,#Gold
                                                  37 #S&P 500
                                                  ]]

#Change Col names
assets_returns_selected.columns = ['CDI', 'FTSE Nareit', 'MSCI IMI/RE 25-50', 'ICE US 7-10 TR','ICE US 20+ TR',
                                   'ICE US TIPS', 'IBOV', 'IHFA', 'IMA-B', 'IMA-B 5', 'IMA-B 5+', 'IRF-M',
                                   'MSCI ACWI', 'GOLD', 'S&P 500']

#Print
print(assets_returns_selected)
display(assets_returns_selected)

"""Calculate correlation"""

corr_matrix = np.corrcoef(assets_returns_selected.dropna(), rowvar = False) #Ignore NAs


# Create a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Correlation Matrix Heatmap')
plt.show()

# Drop assets based on correlation
assets_returns_selected = assets_returns_selected.drop(columns = ['MSCI IMI/RE 25-50', 'ICE US TIPS'],
                                                       axis = 1) #drop columns

display(assets_returns_selected)
np.mean(assets_returns_selected, axis = 0)

"""Fill IHFA Data"""

#X are regressors
ihfa_fill = assets_returns_selected.dropna() #Select rows without NA in IHFA
ihfa_fill_X = ihfa_fill.drop(columns = ['IHFA'], axis = 1)
ihfa_fill_X = sm.add_constant(ihfa_fill_X) #add a constant
ihfa_fill_Y = ihfa_fill.loc[:, 'IHFA'] #Y is IHFA


model = sm.OLS(ihfa_fill_Y, ihfa_fill_X).fit() #Run OLS regression

print(model.summary())

new_data_X = assets_returns_selected[assets_returns_selected['IHFA'].isna()] #Subset only rows with NAs
new_data_X.drop(columns = ['IHFA'], axis = 1, inplace = True) #Remove IHFA
new_data_X.dropna(inplace = True) #Remove NaN rows


IHFA_fill = model.predict(sm.add_constant(new_data_X)) #Fill missing IHFA

assets_returns_selected_complete = assets_returns_selected.dropna(subset = ['IMA-B']) #Drop based on IMA-B

assets_returns_selected_complete['IHFA'].fillna(pd.Series(IHFA_fill), inplace = True) #Replace NaN in IHFA for predicted values

display(assets_returns_selected_complete)

"""Adjust active returns for Ibov"""

import numpy as np

np.random.seed(1)

active_returns = np.random.normal(loc = 0.004, scale =  0.013, size = assets_returns_selected_complete.shape[0])

print(np.mean(active_returns))
print(np.std(active_returns))



assets_returns_selected_complete['IBOV'] = assets_returns_selected_complete['IBOV'] + active_returns

print(np.mean(assets_returns_selected_complete['IBOV']))
print(np.std(assets_returns_selected_complete['IBOV']))
display(assets_returns_selected_complete)
#assets_returns_selected_complete.to_excel("retornos.xlsx", sheet_name = 'Sheet1')
#from google.colab import files

#files.download('retornos.xlsx')

"""Start Backtest

Extract Expectations
"""

#Extract expectations
expected_returns_1y =  pd.read_excel('Base.xlsx', #Workbook path
                       sheet_name = '1Y Forecasts', #Spreadsheet name
                       usecols = range(1,46), #Specify columns to use
                       skiprows = 2, #Skip first two rows
                       nrows = 18, #Specify quantity of rows to use
                       header = None #No headers
                   )

expected_returns_1y = expected_returns_1y.iloc[:,# All rows
                                              [   0,#CDI
                                                  2, #FTSE Nareit Equty REITs + USD
                                                  12, #7-10 Treasury + USD
                                                  14, #20+ Treasury + USD
                                                  24, #Ibov
                                                  27, #IHFA
                                                  28, #IMA-B
                                                  29, #IMA-B 5
                                                  30, #IMA-B 5+
                                                  31, #IRF-M
                                                  32, #MSCI ACWI
                                                  36,#Gold
                                                  37 #S&P 500
                                                  ]]


#Change Col names
expected_returns_1y.columns = ['CDI', 'FTSE Nareit', 'ICE US 7-10 TR','ICE US 20+ TR',
                                   'IBOV', 'IHFA', 'IMA-B', 'IMA-B 5', 'IMA-B 5+', 'IRF-M',
                                   'MSCI ACWI', 'GOLD', 'S&P 500']


expected_returns_3y = pd.read_excel('Base.xlsx', #Workbook path
                   sheet_name = '3Y Forecasts', #Spreadsheet name
                   usecols = range(1,46), #Specify columns to use
                   skiprows = 2, #Skip first two rows
                   nrows = 18, #Specify quantity of rows to use
                   header = None #No headers
                   )



expected_returns_3y = expected_returns_3y.iloc[:,# All rows
                                              [   0,#CDI
                                                  2, #FTSE Nareit Equty REITs + USD
                                                  12, #7-10 Treasury + USD
                                                  14, #20+ Treasury + USD
                                                  24, #Ibov
                                                  27, #IHFA
                                                  28, #IMA-B
                                                  29, #IMA-B 5
                                                  30, #IMA-B 5+
                                                  31, #IRF-M
                                                  32, #MSCI ACWI
                                                  36,#Gold
                                                  37 #S&P 500
                                                  ]]


#Change Col names
expected_returns_3y.columns = ['CDI', 'FTSE Nareit', 'ICE US 7-10 TR','ICE US 20+ TR',
                                   'IBOV', 'IHFA', 'IMA-B', 'IMA-B 5', 'IMA-B 5+', 'IRF-M',
                                   'MSCI ACWI', 'GOLD', 'S&P 500']

expected_returns_5y = pd.read_excel('Base.xlsx', #Workbook path
                   sheet_name = '5Y Forecasts', #Spreadsheet name
                   usecols = range(1,46), #Specify columns to use
                   skiprows = 2, #Skip first two rows
                   nrows = 18, #Specify quantity of rows to use
                   header = None #No headers
                   )


expected_returns_5y = expected_returns_5y.iloc[:,# All rows
                                              [   0,#CDI
                                                  2, #FTSE Nareit Equty REITs + USD
                                                  12, #7-10 Treasury + USD
                                                  14, #20+ Treasury + USD
                                                  24, #Ibov
                                                  27, #IHFA
                                                  28, #IMA-B
                                                  29, #IMA-B 5
                                                  30, #IMA-B 5+
                                                  31, #IRF-M
                                                  32, #MSCI ACWI
                                                  36,#Gold
                                                  37 #S&P 500
                                                  ]]


#Change Col names
expected_returns_5y.columns = ['CDI', 'FTSE Nareit', 'ICE US 7-10 TR','ICE US 20+ TR',
                                   'IBOV', 'IHFA', 'IMA-B', 'IMA-B 5', 'IMA-B 5+', 'IRF-M',
                                   'MSCI ACWI', 'GOLD', 'S&P 500']

"""Run Backtest

Create constraints for constrained optimizations
"""

#Identify classes to apply group constraints
class_mapper = {
    "CDI": "RF",
    "FTSE Nareit": "Exterior",
    "ICE US 7-10 TR": "Exterior",
    "ICE US 20+ TR": "Exterior",
    "IBOV": "RV",
    "IHFA": "Estruturado",
    "IMA-B": "RF",
    "IMA-B 5": "RF",
    "IMA-B 5+": "RF",
    "IRF-M": "RF",
    "MSCI ACWI": "Exterior",
    "GOLD": "Ouro",
    "S&P 500": "Exterior",
}

#Group Constraints
class_upper = {
    "RV": 0.7, #less than 70% in Equities
    "Exterior": 0.1, #less than 10% in Externo
    "Estruturado": 0.15, #less than 15% in Hedge Funds
    "Ouro": 0.03 #less than 3% in Gold
}

class_lower = {
}
print(class_mapper)
print(class_upper)
print(class_lower)

buffer_period = 60
assets_returns_sample = assets_returns_selected_complete.iloc[0:buffer_period,] #Subset returns
historical_mean_returns = assets_returns_sample.mean() #Take historical means
historical_sd_returns = assets_returns_sample.std() #Take historical means
historical_sharpe = historical_mean_returns/historical_sd_returns #Take Sharpe

expected_returns_1y_period = expected_returns_1y.iloc[(d-buffer_period)//12,] #Int dividsion

historical_cov_matrix = np.cov(assets_returns_sample,
                                   rowvar = False) #Each col represents a variable


#historical_mean_returns.plot.barh(figsize=(10,6));
#historical_sd_returns.plot.barh(figsize=(10,6));
#historical_sharpe.plot.barh(figsize=(10,6));

expected_returns_5y_period.plot.barh(figsize=(10,6));

"""EW Portfolios"""

#EW Portfolio
num_assets = len(historical_mean_returns)
ew_weights = 1/num_assets

"""Max Return Conservador - Histórico

MVO - Max Return
"""

###MAX RETURN - Expectativas + Historical
#######################################
from sklearn.covariance import LedoitWolf
from pypfopt.risk_models import CovarianceShrinkage

number_of_periods = assets_returns_selected_complete.shape[0] #Number of periods
buffer_period = 60 #Buffer period
rebalancing_freq = 12 #Annual rebalancing
rebalancing_periods = (number_of_periods - buffer_period)//12 #How many periods of rebalancing
last_rebalancing = (rebalancing_periods * 12) + buffer_period #Last rebalancing

weights_backtest_mvo = pd.DataFrame(columns=assets_returns_selected_complete.columns)  # Initialize DataFrame with asset names

returns_backtest_mvo = [] #Int list ot store returns

#Parameters
shrinkage_parameter_mean_ret = 0.5 #How much to shrink estimates to historical avg?
target_risk = 0.004 #Risk Budget
gamma_constraint = 0.01 #Diversification constraint 0.0050 is a good call for mvo at 0.5 shrinkage

#Rebalancing dates
dates = []
for year in list(range(2008, 2024)):
    date = datetime.date(year, 10, 1)
    dates.append(date)

date_vector = np.array(dates)


for d in range(buffer_period, number_of_periods, rebalancing_freq):
    #Get sample and calculate inputs
    assets_returns_sample = assets_returns_selected_complete.iloc[0:d,]  # Subset returns

    historical_mean_returns_period = assets_returns_sample.mean()
    historical_cov_matrix_period = np.cov(assets_returns_sample, rowvar=False)

    shrunk = LedoitWolf().fit(assets_returns_sample)   #Numpy
    shrunk_cov = shrunk.covariance_

    #shrunk = CovarianceShrinkage(assets_returns_sample, returns_data = True).ledoit_wolf()
    #shrunk_cov = shrunk/100
    expected_returns_period = expected_returns_5y.iloc[(d-buffer_period)//12,] #Int dividsion
    #Shrink to mean avg
    shrunk_mean_ret = historical_mean_returns_period*shrinkage_parameter_mean_ret + expected_returns_period*(1-shrinkage_parameter_mean_ret)

    # Optimization
    ##############################
    ef_mvo = EfficientFrontier(shrunk_mean_ret, historical_cov_matrix_period) #Create instance
    ef_mvo.add_sector_constraints(sector_mapper=class_mapper, sector_upper=class_upper, sector_lower=class_lower) #Sector constraints
    ef_mvo.add_objective(objective_functions.L2_reg, gamma = gamma_constraint) #gamma is tuning parm
    ef_mvo.efficient_risk(target_volatility=target_risk) #Set target vol
    weights_mvo = ef_mvo.clean_weights()

    # Append to DataFrame
    new_index = 0 if len(weights_backtest_mvo) == 0 else weights_backtest_mvo.index[-1] + 1
    weights_backtest_mvo = pd.concat([weights_backtest_mvo, pd.DataFrame(weights_mvo, index=[new_index])])

    # Take out-of-sample returns
    oos_length = (number_of_periods - last_rebalancing) if d == last_rebalancing else rebalancing_freq  # Determine the length of the out-of-sample period. If last period, oos_length = to remaining periods
    assets_returns_oos = assets_returns_selected_complete.iloc[d:d + oos_length,]

    # Calculate port out-of-sample returns
    returns_times_weights = assets_returns_oos * weights_mvo
    returns_backtest_mvo.append(returns_times_weights.sum(axis=1))
    print("Rebalancing Period nº")
    print(d)
    print(returns_times_weights.sum(axis=1))

# Convert the list of returns to a numpy array
returns_backtest_mvo = np.concatenate(returns_backtest_mvo)


weights_backtest_mvo.index = date_vector #Set rownames as dates
display(weights_backtest_mvo)


#Calculate some metrics
mean_ret_backtest_mvo = np.mean(returns_backtest_mvo) #Take mean ret
sd_ret_backtest_mvo = np.std(returns_backtest_mvo) #Take std
sharpe_ret_backtest_mvo = mean_ret_backtest_mvo/sd_ret_backtest_mvo #Take Sharpe

print("mean ret:")
print(mean_ret_backtest_mvo)

print("sd ret:")
print(sd_ret_backtest_mvo)

print("sharpe ret:")
print(sharpe_ret_backtest_mvo)

#Plot
#print(weights_mvo)
pd.Series(weights_mvo).plot.pie(figsize=(10,10));

#Efficient Frontier
#cla = CLA(historical_mean_returns, historical_cov_matrix)
#cla.max_sharpe()
#cla.portfolio_performance(verbose=True);
#ax = plotting.plot_efficient_frontier(cla, showfig=False)



import pandas as pd

returns_backtest_mvo_df = pd.DataFrame(returns_backtest_mvo)
returns_backtest_mvo_df.to_excel('mvo.xlsx', sheet_name='Sheet1')

# Download the file to your local computer (optional)
from google.colab import files
files.download('mvo.xlsx')

"""Set constraints for Risk Parity"""

asset_classes = {'Assets': ['CDI','FTSE Nareit','ICE US 7-10 TR','ICE US 20+ TR','IBOV','IHFA','IMA-B','IMA-B 5',
                            'IMA-B 5+','IRF-M','MSCI ACWI','GOLD','S&P 500'],
                 'Industry': ['RF','Exterior',
                              'Exterior', 'Exterior',
                              'RV','Estruturado','RF',
                              'RF','RF','RF',
                              'Exterior','Gold','Exterior']}

asset_classes = pd.DataFrame(asset_classes)
asset_classes = asset_classes.sort_values(by=['Assets'])

constraints = {'Disabled': [False, False, False, False, False,False],
               'Type': ['All Assets', 'Classes', 'Classes', 'Classes',
                        'Classes', 'Classes'],
               'Set': ['', 'Industry', 'Industry', 'Industry', 'Industry', 'Industry'],
               'Position': ['', 'RF', 'Exterior', 'RV',
                            'Estruturado', 'Gold'],
               'Sign': ['<=', '<=', '<=', '<=', '<=', '<='],
               'Weight': [1, 1, 0.1, 0.7, 0.15, 0.03],
               'Type Relative': ['', '', '', '', '',''],
               'Relative Set': ['', '', '', '', '',''],
               'Relative': ['', '', '', '', '',''],
               'Factor': ['', '', '', '', '','']}

constraints = pd.DataFrame(constraints)

display(constraints)

"""RiskParity"""

###Risk Parity - Expectativas + Historical
#######################################
import riskfolio as rp

number_of_periods = assets_returns_selected_complete.shape[0] #Number of periods
buffer_period = 60 #Buffer period
rebalancing_freq = 12 #Annual rebalancing
rebalancing_periods = (number_of_periods - buffer_period)//12 #How many periods of rebalancing
last_rebalancing = (rebalancing_periods * 12) + buffer_period #Last rebalancing

weights_backtest_mvo = pd.DataFrame(columns=assets_returns_selected_complete.columns)  # Initialize DataFrame with asset names

returns_backtest_mvo = [] #Int list ot store returns

#Parameters
shrinkage_parameter_mean_ret = 0.5 #How much to shrink estimates to historical avg?
target_risk = 0.02 #Risk Budget
gamma_constraint = 0.05 #Diversification constraint 0.0050 is a good call for mvo at 0.5 shrinkage
lower_ret_percentage = 1.375 #Min return

#Rebalancing dates
dates = []
for year in list(range(2008, 2024)):
    date = datetime.date(year, 10, 1)
    dates.append(date)

date_vector = np.array(dates)


for d in range(buffer_period, number_of_periods, rebalancing_freq):
    #Get sample and calculate inputs
    assets_returns_sample = assets_returns_selected_complete.iloc[0:d,]  # Subset returns

    historical_mean_returns_period = assets_returns_sample.mean()
    historical_cov_matrix_period = np.cov(assets_returns_sample, rowvar=False)

    expected_returns_period = expected_returns_5y.iloc[(d-buffer_period)//12,] #Int dividsion
    #Shrink to mean avg
    shrunk_mean_ret = historical_mean_returns_period*shrinkage_parameter_mean_ret + expected_returns_period*(1-shrinkage_parameter_mean_ret)

    #Set risk-free
    risk_free_period = shrunk_mean_ret.values[0]*lower_ret_percentage
    print(risk_free_period)


    # Risk Parity Portfolios
    ##############################
    port = rp.Portfolio(returns = assets_returns_sample)
    port.assets_stats(method_mu='hist', method_cov='hist', d=0.94)
    A, B = rp.assets_constraints(constraints, asset_classes)
    port.ainequality = A
    port.binequality = B
    port.lowerret = risk_free_period
    weights_mvo = port.rp_optimization(model='Classic', rm='MV', rf=0, b=None, hist=True)

    # Append the weights_mvo as a new row to weights_backtest_mvo
    weights_backtest_mvo.loc[len(weights_backtest_mvo)] = weights_mvo.values.flatten()

    # Take out-of-sample returns
    oos_length = (number_of_periods - last_rebalancing) if d == last_rebalancing else rebalancing_freq  # Determine the length of the out-of-sample period. If last period, oos_length = to remaining periods
    assets_returns_oos = assets_returns_selected_complete.iloc[d:d + oos_length,]

    # Calculate port out-of-sample returns
    returns_times_weights = assets_returns_oos * weights_mvo.values.flatten()
    returns_backtest_mvo.append(returns_times_weights.sum(axis=1))
    #print("Rebalancing Period nº")
    #print(d)
    #print(returns_times_weights.sum(axis=1))

# Convert the list of returns to a numpy array
returns_backtest_mvo = np.concatenate(returns_backtest_mvo)

weights_backtest_mvo.index = date_vector #Set rownames as dates
display(weights_backtest_mvo)


#Calculate some metrics
mean_ret_backtest_mvo = np.mean(returns_backtest_mvo) #Take mean ret
sd_ret_backtest_mvo = np.std(returns_backtest_mvo) #Take std
sharpe_ret_backtest_mvo = mean_ret_backtest_mvo/sd_ret_backtest_mvo #Take Sharpe

print("mean ret:")
print(mean_ret_backtest_mvo)

print("sd ret:")
print(sd_ret_backtest_mvo)

print("sharpe ret:")
print(sharpe_ret_backtest_mvo)

#Plot
#print(weights_mvo)
# Plot pie chart of portfolio weights
weights_mvo.plot.pie(subplots=True, figsize=(10, 10), legend=None);
ax = rp.plot_pie(w=weights_mvo, title='Risk Parity Variance', others=0.05, nrow=25, cmap = "tab20",
                 height=6, width=10, ax=None)

import matplotlib.pyplot as plt

fig, ax = plt.subplots(figsize=(10,6))

# Plotting the risk composition of the portfolio
ax = rp.plot_risk_con(weights_mvo, cov=port.cov, returns=port.returns, rm='MV', rf=0, alpha=0.05,
                      color="tab:blue", height=6, width=10, ax=ax)

# Plotting equal risk contribution line
a1 = rp.Sharpe_Risk(weights_mvo, cov=port.cov, returns=port.returns, rm='MV', rf=0, alpha=0.05)
ax.axhline(y=a1/13 * 252**0.5, color='r', linestyle='-')

plt.show()
#Efficient Frontier
#cla = CLA(historical_mean_returns, historical_cov_matrix)
#cla.max_sharpe()
#cla.portfolio_performance(verbose=True);
#ax = plotting.plot_efficient_frontier(cla, showfig=False)